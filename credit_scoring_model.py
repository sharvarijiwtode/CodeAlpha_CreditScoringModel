# -*- coding: utf-8 -*-
"""credit_scoring_model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1C5BvGBPZ5Bv3n7yHsw1kHV-oaBNbGrWx
"""

import pandas as pd

# Define column names as per the documentation
columns = [
    'Status_of_existing_checking_account', 'Duration_in_month', 'Credit_history',
    'Purpose', 'Credit_amount', 'Savings_account_bonds', 'Present_employment_since',
    'Installment_rate_in_percentage_of_disposable_income', 'Personal_status_and_sex',
    'Other_debtors_guarantors', 'Present_residence_since', 'Property',
    'Age_in_years', 'Other_installment_plans', 'Housing',
    'Number_of_existing_credits_at_this_bank', 'Job', 'Number_of_people_being_liable_to_provide_maintenance_for',
    'Telephone', 'Foreign_worker', 'Credit_risk'
]

# Load the dataset
df = pd.read_csv('german.data', sep=' ', header=None, names=columns)

# Encode target variable: 1 -> 0 (good), 2 -> 1 (bad)
df['Credit_risk'] = df['Credit_risk'].map({1: 0, 2: 1})

import pandas as pd

# Define column names from UCI documentation
columns = [
    'Status_of_existing_checking_account', 'Duration_in_month', 'Credit_history',
    'Purpose', 'Credit_amount', 'Savings_account_bonds', 'Present_employment_since',
    'Installment_rate', 'Personal_status_and_sex', 'Other_debtors_guarantors',
    'Present_residence_since', 'Property', 'Age', 'Other_installment_plans',
    'Housing', 'Number_of_existing_credits', 'Job',
    'Number_of_people_liable', 'Telephone', 'Foreign_worker', 'Credit_risk'
]

# Load dataset
df = pd.read_csv("german.data", sep=' ', header=None, names=columns)

# Encode target: 1 = good, 2 = bad â†’ 0 = good, 1 = bad
df['Credit_risk'] = df['Credit_risk'].map({1: 0, 2: 1})

print(df['Credit_risk'].value_counts())
print(df.describe())
print(df.isnull().sum())

from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.model_selection import train_test_split

# Encode categorical features
le = LabelEncoder()
for col in df.select_dtypes(include='object').columns:
    df[col] = le.fit_transform(df[col])

# Separate features and target
X = df.drop('Credit_risk', axis=1)
y = df['Credit_risk']

# Feature scaling
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Train/Test Split
X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y, test_size=0.2, random_state=42
)

from sklearn.ensemble import RandomForestClassifier

# Train model
model = RandomForestClassifier(random_state=42)
model.fit(X_train, y_train)

from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score
import seaborn as sns
import matplotlib.pyplot as plt

# Predict
y_pred = model.predict(X_test)
y_prob = model.predict_proba(X_test)[:, 1]

# Print metrics
print(classification_report(y_test, y_pred))
print("ROC AUC Score:", roc_auc_score(y_test, y_prob))

# Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Confusion Matrix")
plt.show()